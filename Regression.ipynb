{"cells":[{"cell_type":"code","source":["# Import Spark SQL and Spark ML libraries\nfrom pyspark.sql.types import *\nfrom pyspark.sql.functions import *\n\nfrom sklearn import cross_validation\nfrom sklearn.metrics import confusion_matrix, precision_recall_fscore_support, accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.regression import LinearRegression , DecisionTreeRegressor\nfrom pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.tuning import ParamGridBuilder, CrossValidator, TrainValidationSplit\nfrom pyspark.ml.evaluation import RegressionEvaluator"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["data = sqlContext.sql(\"SELECT Cast(loan_amnt as Double),Cast(Substring(int_rate,1,4) as Double) as int_rate,Cast(total_pymnt as Double),Cast(installment as Double) as label from loan\")\ndata=data.dropna();\ndata.show(30)\ndata.printSchema()"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["#Feature selection\ndata_fea = data.select(\"int_rate\",\"label\",\"loan_amnt\")\n\n#Data split to train and test samples. 70% for training and 30% for testing\nsplits = data_fea.randomSplit([0.7, 0.3])\ntrain = splits[0]\ntest = splits[1]\nprint \"We have %d training examples and %d test examples.\" % (train.count(), test.count())\n#display(train)"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["#Model1 - Linear Regression\nvectorAssembler = VectorAssembler(inputCols=[\"int_rate\",\"loan_amnt\"], outputCol=\"features\")\nlr = LinearRegression(labelCol=\"label\",featuresCol=\"features\", maxIter=10, regParam=0.3)\npipeline = Pipeline(stages=[vectorAssembler, lr])"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["#Using trainvalidationsplit\n#It's going to use 80% of the data that it's got in its training set to train the model and then the remaining 20% is going to use to validate the trained model.\nparamGrid1 = ParamGridBuilder().addGrid(lr.regParam, [0.3, 0.01]).addGrid(lr.maxIter, [10, 5]).build()\ntvs = TrainValidationSplit(estimator=pipeline, evaluator=RegressionEvaluator(), estimatorParamMaps=paramGrid1, trainRatio=0.8)\nmodel1 = tvs.fit(train)"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["prediction1 = model1.transform(test)\n# LinearRegression\npredicted1 = prediction1.select(\"*\")\ndisplay(predicted1)"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["# LinearRegression: predictionCol=\"prediction\", metricName=\"rmse\"\nevaluator1 = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\nrmse1 = evaluator1.evaluate(prediction1)\nprint \"Root Mean Square Error (RMSE):\", rmse1"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["#Model2 - GBT regressor\nvectorAssembler2 = VectorAssembler(inputCols=[\"int_rate\",\"loan_amnt\"], outputCol=\"features\")\ndt = DecisionTreeRegressor(labelCol=\"label\", featuresCol=\"features\")\npipeline2 = Pipeline(stages=[vectorAssembler2, dt])"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["# Define a grid of hyperparameters to test:\n#  - maxDepth: max depth of each decision tree in the GBT ensemble\n#  - maxIter: iterations, i.e., number of trees in each GBT ensemble\n\nparamGrid2 = ParamGridBuilder()\\\n  .addGrid(dt.maxDepth, [2, 10])\\\n  .build()\n# We define an evaluation metric.  This tells CrossValidator how well we are doing by comparing the true labels with predictions.\n#evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=gbt.getLabelCol(), predictionCol=gbt.getPredictionCol())\n# Declare the CrossValidator, which runs model tuning for us.\n#cv = CrossValidator(estimator=gbt, evaluator=RegressionEvaluator(), estimatorParamMaps=paramGrid2, numFolds=10)\n\ntvs2 = TrainValidationSplit(estimator=pipeline2, evaluator=RegressionEvaluator(), estimatorParamMaps=paramGrid2, trainRatio=0.8)\nmodel2 = tvs2.fit(train)"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["prediction2 = model2.transform(test)\npredicted2 = prediction2.select(\"*\")\ndisplay(predicted2)\n"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["rmse = evaluator1.evaluate(prediction2)\nprint \"RMSE on our test set: %g\" % rmse"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":12}],"metadata":{"name":"Regression","notebookId":1210975120601207},"nbformat":4,"nbformat_minor":0}
