{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a href=\"http://www.calstatela.edu/centers/hipic\"><img align=\"left\" src=\"https://avatars2.githubusercontent.com/u/4156894?v=3&s=100\"><image/>\n",
    "</a>\n",
    "<img align=\"right\" alt=\"California State University, Los Angeles\" src=\"http://www.calstatela.edu/sites/default/files/groups/California%20State%20University%2C%20Los%20Angeles/master_logo_full_color_horizontal_centered.svg\" style=\"width: 360px;\"/>\n",
    "\n",
    "# CIS5560 Term Project Tutorial\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Authors:Hemamalini Madhanguru,Lakshmi Sundararajan,Pallavi Attimakula\n",
    "\n",
    "#### Instructor: [Jongwook Woo](https://www.linkedin.com/in/jongwook-woo-7081a85)\n",
    "\n",
    "#### Date: 05/18/2017\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Creating a Regression Model\n",
    "In this exercise, you will implement a regression model using Linear Regression that uses features of lending loan clubs to predict the value of the installments.\n",
    "\n",
    "You should follow the steps below to build, train and test the model from the source data:\n",
    "1. Build a schema of a source data for its Data Frame\n",
    "2. Load the Source Data to the schema\n",
    "3. Prepare the data with the features (input columns, output column as label)\n",
    "4. Split the data using data.randomSplit(): Training and Testing\n",
    "5. Transform the columns to a vector using VectorAssembler\n",
    "6. set features and label from the vector\n",
    "7. Build a LinearRegression Model with the label and features\n",
    "8. Train the model\n",
    "9. Prepare the testing Data Frame with features and label from the vector; Rename label to trueLabel\n",
    "10. Predict and test the testing Data Frame using the model trained at the step 8\n",
    "11. Compare the predicted result and trueLabel\n",
    "\n",
    "#### Import Spark SQL and Spark ML Libraries\n",
    "First, import the libraries you will need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Spark SQL and Spark ML libraries\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "from sklearn import cross_validation\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import LinearRegression , DecisionTreeRegressor\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator, TrainValidationSplit\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the Data\n",
    "Most modeling begins with exhaustive exploration and preparation of the data. In this example, you will simply select a subset of columns to use as features as well as the ArrDelay column, which will be the label your model will predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = sqlContext.sql(\"SELECT ACTIVITY,NAME, CAST(count(VIOLATION_CODE) AS DOUBLE) as Total_violations,grade, CAST(score as DOUBLE) as label, CAST(sum(points) as DOUBLE) as Violation_points FROM rest_vio where score >= '65' group by NAME,ACTIVITY,grade,score\")\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the Data\n",
    "It is common practice when building supervised machine learning models to split the source data, using some of it to train the model and reserving some to test the trained model. In this exercise, you will use 70% of the data for training, and reserve 30% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Feature selection\n",
    "data_fea = data.select(\"label\",\"Total_violations\")\n",
    "#Data split to train and test samples. 70% for training and 30% for testing\n",
    "splits = data_fea.randomSplit([0.7, 0.3])\n",
    "train = splits[0]\n",
    "test = splits[1].withColumnRenamed(\"label\", \"trueLabel\")\n",
    "print \"We have %d training examples and %d test examples.\" % (train.count(), test.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the Training Data\n",
    "To train the regression model, you need a training data set that includes a vector of numeric features, and a label column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Model1 - Linear Regression\n",
    "vectorAssembler = VectorAssembler(inputCols=[\"Total_violations\"], outputCol=\"features\")\n",
    "lr = LinearRegression(labelCol=\"label\",featuresCol=\"features\", maxIter=10, regParam=0.3)\n",
    "pipeline = Pipeline(stages=[vectorAssembler, lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using trainvalidationsplit\n",
    "It's going to use 80% of the data that it's got in its training set to train the model and then the remaining 20% is going to use to validate the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-7fb0a4d52430>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mparamGrid1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mParamGridBuilder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregParam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaxIter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtvs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrainValidationSplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mRegressionEvaluator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimatorParamMaps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparamGrid1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainRatio\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtvs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'lr' is not defined"
     ]
    }
   ],
   "source": [
    "paramGrid1 = ParamGridBuilder().addGrid(lr.regParam, [0.3, 0.01]).addGrid(lr.maxIter, [10, 5]).build()\n",
    "tvs = TrainValidationSplit(estimator=pipeline, evaluator=RegressionEvaluator(), estimatorParamMaps=paramGrid1, trainRatio=0.8)\n",
    "model1 = tvs.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Model\n",
    "Now you're ready to use the transform method of the model to generate some predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-f2c99e9b079b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprediction1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# LinearRegression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpredicted1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprediction1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"features\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"prediction\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"trueLabel\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicted1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model1' is not defined"
     ]
    }
   ],
   "source": [
    "prediction1 = model1.transform(test)\n",
    "# LinearRegression\n",
    "predicted1 = prediction1.select(\"features\", \"prediction\", \"trueLabel\")\n",
    "display(predicted1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE\n",
    "The regression line predicts the average value associated with a given a x value. To do this we use the root mean square error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LinearRegression: predictionCol=\"prediction\", metricName=\"rmse\"\n",
    "evaluator1 = RegressionEvaluator(labelCol=\"trueLabel\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse1 = evaluator.evaluate(prediction1)\n",
    "print \"Root Mean Square Error (RMSE):\", rmse1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boost Regressor\n",
    "Gbt is a learning algorithm for regression. It supports both continous and categorical features. \n",
    "This operation is ported from Spark ML.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Model2 - GBT regressor\n",
    "vectorAssembler2 = VectorAssembler(inputCols=[\"Total_violations\"], outputCol=\"features\")\n",
    "dt = DecisionTreeRegressor(labelCol=\"label\", featuresCol=\"features\")\n",
    "pipeline2 = Pipeline(stages=[vectorAssembler2, dt])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameter Grid Builder\n",
    "Builder for a param grid used in grid search-based model selection. Validation for hyper-parameter tuning splits the input dataset into train and validation sets, and uses evaluation metric on the validation set to select the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a grid of hyperparameters to test:\n",
    "#  - maxDepth: max depth of each decision tree in the GBT ensemble\n",
    "#  - maxIter: iterations, i.e., number of trees in each GBT ensemble\n",
    "\n",
    "paramGrid2 = ParamGridBuilder()\\\n",
    "  .addGrid(gbt.maxDepth, [2, 10])\\\n",
    "  .addGrid(gbt.maxIter, [10, 200])\\\n",
    "  .build()\n",
    "# We define an evaluation metric.  This tells CrossValidator how well we are doing by comparing the true labels with predictions.\n",
    "#evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=gbt.getLabelCol(), predictionCol=gbt.getPredictionCol())\n",
    "# Declare the CrossValidator, which runs model tuning for us.\n",
    "#cv = CrossValidator(estimator=gbt, evaluator=RegressionEvaluator(), estimatorParamMaps=paramGrid2, numFolds=10)\n",
    "\n",
    "tvs2 = TrainValidationSplit(estimator=pipeline2, evaluator=RegressionEvaluator(), estimatorParamMaps=paramGrid2, trainRatio=0.8)\n",
    "model2 = tvs2.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction2 = model2.transform(test)\n",
    "predicted2 = prediction2.select(\"features\", \"prediction\", \"trueLabel\")\n",
    "display(predicted2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rmse = evaluator.evaluate(predictions2)\n",
    "print \"RMSE on our test set: %g\" % rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "1. [Markdown Cells in Jupyter](http://jupyter-notebook.readthedocs.io/en/latest/examples/Notebook/Working%20With%20Markdown%20Cells.html)\n",
    "1. [Markdown Cheatshee](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet)\n",
    "1. [Markdown Guide](https://help.ghost.org/hc/en-us/articles/224410728-Markdown-Guide)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2 with Spark 2.0",
   "language": "python",
   "name": "python2-spark20"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}